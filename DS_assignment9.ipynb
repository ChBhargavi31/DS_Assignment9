{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5fae70f",
   "metadata": {},
   "source": [
    "Linear regression is a statistical method determining the relationship between two or more variables. \n",
    "It involves using an independent or known variable to predict the dependent or response variable. \n",
    "Simple: This type involves estimating the relationship between two quantitative variables, \n",
    "        such as the value of a dependent variable at a particular value of the independent variable.\n",
    "Multiple: In this type, you can determine the relationship between several independent variables \n",
    "         and a dependent variable.\n",
    "In this Analysis taken dataset is about the scores of a race that are mathscore,readingscore,writingscore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d42d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries are imported\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4aa279c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>mathscore</th>\n",
       "      <th>readingscore</th>\n",
       "      <th>writingscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>group B</td>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>group B</td>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>group A</td>\n",
       "      <td>61</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>group A</td>\n",
       "      <td>68</td>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>group B</td>\n",
       "      <td>66</td>\n",
       "      <td>86</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>group C</td>\n",
       "      <td>79</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>group D</td>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>group C</td>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>group C</td>\n",
       "      <td>76</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>group C</td>\n",
       "      <td>82</td>\n",
       "      <td>88</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       race  mathscore  readingscore  writingscore\n",
       "0   group B         71            79            81\n",
       "1   group B         39            48            47\n",
       "2   group A         61            67            64\n",
       "3   group A         68            79            82\n",
       "4   group B         66            86            77\n",
       "..      ...        ...           ...           ...\n",
       "95  group C         79            85            86\n",
       "96  group D         63            73            76\n",
       "97  group C         47            61            61\n",
       "98  group C         76            90            87\n",
       "99  group C         82            88            92\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Dataset is imported and displayed\n",
    "dataset= pd.read_csv(r'C:\\Users\\DELL\\Downloads\\exams.csv')\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f99d2b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with column removed:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mathscore</th>\n",
       "      <th>readingscore</th>\n",
       "      <th>writingscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>86</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>79</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>76</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>82</td>\n",
       "      <td>88</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mathscore  readingscore  writingscore\n",
       "0          71            79            81\n",
       "1          39            48            47\n",
       "2          61            67            64\n",
       "3          68            79            82\n",
       "4          66            86            77\n",
       "..        ...           ...           ...\n",
       "95         79            85            86\n",
       "96         63            73            76\n",
       "97         47            61            61\n",
       "98         76            90            87\n",
       "99         82            88            92\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Race column is removed because the predicted value it gives when doing the onehotencoding is\n",
    "#not accurate\n",
    "dataset1 = dataset.drop([\"race\"],axis=1)\n",
    "print(\"\\nDataFrame with column removed:\")\n",
    "display(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d9b2f81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 71  79]\n",
      " [ 39  48]\n",
      " [ 61  67]\n",
      " [ 68  79]\n",
      " [ 66  86]\n",
      " [ 57  49]\n",
      " [ 81  73]\n",
      " [ 53  54]\n",
      " [ 54  51]\n",
      " [ 81  69]\n",
      " [ 59  54]\n",
      " [ 72  58]\n",
      " [ 74  64]\n",
      " [ 47  54]\n",
      " [ 67  64]\n",
      " [ 62  67]\n",
      " [ 94  95]\n",
      " [ 79  69]\n",
      " [ 31  39]\n",
      " [ 65  63]\n",
      " [ 77  86]\n",
      " [ 33  28]\n",
      " [ 80  80]\n",
      " [ 43  37]\n",
      " [ 53  74]\n",
      " [ 76  76]\n",
      " [ 69  77]\n",
      " [100  95]\n",
      " [ 64  68]\n",
      " [ 56  59]\n",
      " [ 69  74]\n",
      " [ 89  87]\n",
      " [ 89  92]\n",
      " [ 85  87]\n",
      " [ 92  93]\n",
      " [ 83  89]\n",
      " [ 85  78]\n",
      " [ 72  87]\n",
      " [ 61  66]\n",
      " [ 69  60]\n",
      " [ 68  69]\n",
      " [ 77  72]\n",
      " [ 70  66]\n",
      " [ 57  76]\n",
      " [ 98  94]\n",
      " [ 71  77]\n",
      " [ 78  84]\n",
      " [ 51  73]\n",
      " [ 93 100]\n",
      " [ 57  71]\n",
      " [ 53  64]\n",
      " [ 76  80]\n",
      " [ 67  64]\n",
      " [ 88  80]\n",
      " [ 84  80]\n",
      " [ 57  52]\n",
      " [ 68  76]\n",
      " [ 55  49]\n",
      " [ 76  90]\n",
      " [ 74  71]\n",
      " [ 69  75]\n",
      " [ 86  84]\n",
      " [ 78  93]\n",
      " [ 79  76]\n",
      " [ 67  71]\n",
      " [ 58  49]\n",
      " [ 45  55]\n",
      " [ 64  74]\n",
      " [ 43  58]\n",
      " [ 67  61]\n",
      " [ 57  57]\n",
      " [ 88  97]\n",
      " [ 57  64]\n",
      " [ 65  59]\n",
      " [ 69  73]\n",
      " [ 58  77]\n",
      " [ 56  59]\n",
      " [ 84  87]\n",
      " [ 85  78]\n",
      " [ 30  40]\n",
      " [ 90  90]\n",
      " [ 65  68]\n",
      " [ 85  93]\n",
      " [100 100]\n",
      " [ 83  76]\n",
      " [ 36  41]\n",
      " [ 84  79]\n",
      " [ 85  84]\n",
      " [ 66  70]\n",
      " [ 71  73]\n",
      " [ 78  73]\n",
      " [ 59  57]\n",
      " [ 77  69]\n",
      " [ 80  92]\n",
      " [ 70  80]\n",
      " [ 79  85]\n",
      " [ 63  73]\n",
      " [ 47  61]\n",
      " [ 76  90]\n",
      " [ 82  88]]\n",
      "[ 81  47  64  82  77  45  71  49  50  64  60  59  63  46  64  64  84  71\n",
      "  44  60  90  25  79  38  70  72  79  99  68  54  70  84  86  81  98  94\n",
      "  73  91  64  63  63  73  54  68  89  72  89  73 100  74  62  79  52  74\n",
      "  76  55  75  47  84  71  73  86  98  81  64  51  51  67  53  56  57  83\n",
      "  58  57  69  77  60  83  86  45  89  56  89 100  81  32  80  86  65  85\n",
      "  72  60  74  93  82  86  76  61  87  92]\n"
     ]
    }
   ],
   "source": [
    "#extracted the dependent and independent variables from the given dataset. \n",
    "X = dataset1.iloc[:, :-1].values\n",
    "y = dataset1.iloc[:, 2].values\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40fa18b",
   "metadata": {},
   "source": [
    "we will split both variables into the test set and training set.\n",
    "We have 30 observations, so we will take 80 observations for the training set and 20 observations for the test set. We are splitting our dataset so that we can train our model using a training dataset and then test the model using a test dataset.\n",
    "Here dataset has multiple columns so for this Multiple linear regression is choosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0907c3d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 78  73]\n",
      " [ 57  57]\n",
      " [ 53  64]\n",
      " [ 98  94]\n",
      " [ 56  59]\n",
      " [ 57  52]\n",
      " [ 33  28]\n",
      " [ 86  84]\n",
      " [ 81  73]\n",
      " [ 79  76]\n",
      " [ 70  66]\n",
      " [ 92  93]\n",
      " [ 83  76]\n",
      " [ 67  64]\n",
      " [ 83  89]\n",
      " [ 69  60]\n",
      " [ 71  77]\n",
      " [ 66  86]\n",
      " [ 57  49]\n",
      " [ 93 100]\n",
      " [ 89  92]\n",
      " [ 77  86]\n",
      " [100 100]\n",
      " [ 76  90]\n",
      " [ 51  73]\n",
      " [ 90  90]\n",
      " [ 79  69]\n",
      " [ 64  74]\n",
      " [ 65  68]\n",
      " [ 53  54]\n",
      " [ 85  84]\n",
      " [ 47  61]\n",
      " [ 76  90]\n",
      " [ 82  88]\n",
      " [ 53  74]\n",
      " [ 59  54]\n",
      " [ 63  73]\n",
      " [ 84  79]\n",
      " [ 68  76]\n",
      " [ 88  97]\n",
      " [ 43  37]\n",
      " [ 80  80]\n",
      " [ 59  57]\n",
      " [ 70  80]\n",
      " [ 31  39]\n",
      " [100  95]\n",
      " [ 66  70]\n",
      " [ 55  49]\n",
      " [ 89  87]\n",
      " [ 58  49]\n",
      " [ 74  64]\n",
      " [ 85  93]\n",
      " [ 69  74]\n",
      " [ 58  77]\n",
      " [ 76  76]\n",
      " [ 47  54]\n",
      " [ 67  61]\n",
      " [ 84  87]\n",
      " [ 36  41]\n",
      " [ 76  80]\n",
      " [ 57  71]\n",
      " [ 85  78]\n",
      " [ 57  64]\n",
      " [ 85  87]\n",
      " [ 78  93]\n",
      " [ 84  80]\n",
      " [ 72  58]\n",
      " [ 94  95]\n",
      " [ 85  78]\n",
      " [ 68  69]\n",
      " [ 71  79]\n",
      " [ 65  59]\n",
      " [ 54  51]\n",
      " [ 56  59]\n",
      " [ 80  92]\n",
      " [ 71  73]\n",
      " [ 64  68]\n",
      " [ 67  71]\n",
      " [ 62  67]\n",
      " [ 81  69]]\n",
      "[ 72  57  62  89  60  55  25  86  71  81  54  98  81  52  94  63  72  77\n",
      "  45 100  86  90 100  84  73  89  71  67  56  49  86  61  87  92  70  60\n",
      "  76  80  75  83  38  79  60  82  44  99  65  47  84  51  63  89  70  77\n",
      "  72  46  56  83  32  79  74  86  58  81  98  76  59  84  73  63  81  57\n",
      "  50  54  93  85  68  64  64  64]\n",
      "[[65 63]\n",
      " [67 64]\n",
      " [57 76]\n",
      " [72 87]\n",
      " [45 55]\n",
      " [68 79]\n",
      " [30 40]\n",
      " [77 72]\n",
      " [61 66]\n",
      " [43 58]\n",
      " [61 67]\n",
      " [39 48]\n",
      " [69 75]\n",
      " [88 80]\n",
      " [79 85]\n",
      " [69 73]\n",
      " [77 69]\n",
      " [69 77]\n",
      " [74 71]\n",
      " [78 84]]\n",
      "[60 64 68 91 51 82 45 73 64 53 64 47 73 74 86 69 74 79 71 89]\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state =10)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "94683156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac20d34",
   "metadata": {},
   "source": [
    "The last step of model is checking the performance of the model.\n",
    "It can be done by predicting the test set result. For prediction, create a y_pred and x_pred vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c73e8f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61.60945701 62.68811538 73.29750848 84.68211668 52.70554213 76.87679349\n",
      " 37.55559629 70.90541045 64.15881231 55.39222139 65.10014672 45.70422939\n",
      " 73.18011783 79.19136751 83.28008173 71.29744902 68.08140723 75.06278665\n",
      " 69.7580901  82.27008534]\n",
      "[71.91540684 55.41215471 61.72684765 93.05666903 57.22616155 50.70548267\n",
      " 26.46556933 82.81938118 72.12139278 74.80807205 64.77677014 91.70336274\n",
      " 75.08271997 62.68811538 87.32006728 59.0601017  75.20011061 83.32881039\n",
      " 47.88147944 98.36136558 90.55604239 84.08409217 98.84199945 87.78076783\n",
      " 70.06153337 88.74203556 68.21873119 71.89547352 66.31612905 52.31350356\n",
      " 82.7507192  58.49087254 87.78076783 86.31007089 71.14019174 52.72547545\n",
      " 70.88547713 77.97538518 74.05279026 95.19405246 35.62419881 78.64207166\n",
      " 55.54947867 77.95545186 36.68292386 94.1353274  68.26745985 47.74415548\n",
      " 85.84937035 47.95014142 63.16874924 91.22272888 72.23878343 74.30750487\n",
      " 74.60208611 51.90153168 59.86411215 85.50606045 38.90890258 78.36742374\n",
      " 68.59083643 77.10271275 62.00149557 85.57472243 90.74209502 78.91671959\n",
      " 57.38341883 93.72335552 77.10271275 67.4634494  77.08277943 57.84411937\n",
      " 49.55816232 57.22616155 89.93808457 71.43477298 66.24746707 69.27745624\n",
      " 65.1688087  68.35605515]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(y_pred)\n",
    "X_pred= regressor.predict(X_train)  \n",
    "print(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2cd2591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9115316662858928\n",
      "Test Score:  0.9076822589881861\n"
     ]
    }
   ],
   "source": [
    "print('Train Score: ', regressor.score(X_train, y_train))  \n",
    "print('Test Score: ', regressor.score(X_test, y_test))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0bae2d",
   "metadata": {},
   "source": [
    "Evaluation Metrics\n",
    "Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1129a859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9076822589881861"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model score - R2 or coeff of determinant\n",
    "# R^2=1–RSS / TSS\n",
    "regressor.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d1373cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.345747294041285\n"
     ]
    }
   ],
   "source": [
    "# Let us check the sum of squared errors by predicting value of y for training cases and \n",
    "# subtracting from the actual y for the training cases\n",
    "\n",
    "mse = np.mean((regressor.predict(X_test) - y_test)**2)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0046fe56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9173648405581636"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6439a7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with new column:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mathscore</th>\n",
       "      <th>readingscore</th>\n",
       "      <th>writingscore</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "      <td>81</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>86</td>\n",
       "      <td>77</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>79</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>76</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>82</td>\n",
       "      <td>88</td>\n",
       "      <td>92</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mathscore  readingscore  writingscore  total\n",
       "0          71            79            81    150\n",
       "1          39            48            47     87\n",
       "2          61            67            64    128\n",
       "3          68            79            82    147\n",
       "4          66            86            77    152\n",
       "..        ...           ...           ...    ...\n",
       "95         79            85            86    164\n",
       "96         63            73            76    136\n",
       "97         47            61            61    108\n",
       "98         76            90            87    166\n",
       "99         82            88            92    170\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset1['total'] = dataset1['mathscore'] + dataset1['readingscore']\n",
    "print(\"\\nDataFrame with new column:\")\n",
    "display(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "443f7fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 71  79]\n",
      " [ 39  48]\n",
      " [ 61  67]\n",
      " [ 68  79]\n",
      " [ 66  86]\n",
      " [ 57  49]\n",
      " [ 81  73]\n",
      " [ 53  54]\n",
      " [ 54  51]\n",
      " [ 81  69]\n",
      " [ 59  54]\n",
      " [ 72  58]\n",
      " [ 74  64]\n",
      " [ 47  54]\n",
      " [ 67  64]\n",
      " [ 62  67]\n",
      " [ 94  95]\n",
      " [ 79  69]\n",
      " [ 31  39]\n",
      " [ 65  63]\n",
      " [ 77  86]\n",
      " [ 33  28]\n",
      " [ 80  80]\n",
      " [ 43  37]\n",
      " [ 53  74]\n",
      " [ 76  76]\n",
      " [ 69  77]\n",
      " [100  95]\n",
      " [ 64  68]\n",
      " [ 56  59]\n",
      " [ 69  74]\n",
      " [ 89  87]\n",
      " [ 89  92]\n",
      " [ 85  87]\n",
      " [ 92  93]\n",
      " [ 83  89]\n",
      " [ 85  78]\n",
      " [ 72  87]\n",
      " [ 61  66]\n",
      " [ 69  60]\n",
      " [ 68  69]\n",
      " [ 77  72]\n",
      " [ 70  66]\n",
      " [ 57  76]\n",
      " [ 98  94]\n",
      " [ 71  77]\n",
      " [ 78  84]\n",
      " [ 51  73]\n",
      " [ 93 100]\n",
      " [ 57  71]\n",
      " [ 53  64]\n",
      " [ 76  80]\n",
      " [ 67  64]\n",
      " [ 88  80]\n",
      " [ 84  80]\n",
      " [ 57  52]\n",
      " [ 68  76]\n",
      " [ 55  49]\n",
      " [ 76  90]\n",
      " [ 74  71]\n",
      " [ 69  75]\n",
      " [ 86  84]\n",
      " [ 78  93]\n",
      " [ 79  76]\n",
      " [ 67  71]\n",
      " [ 58  49]\n",
      " [ 45  55]\n",
      " [ 64  74]\n",
      " [ 43  58]\n",
      " [ 67  61]\n",
      " [ 57  57]\n",
      " [ 88  97]\n",
      " [ 57  64]\n",
      " [ 65  59]\n",
      " [ 69  73]\n",
      " [ 58  77]\n",
      " [ 56  59]\n",
      " [ 84  87]\n",
      " [ 85  78]\n",
      " [ 30  40]\n",
      " [ 90  90]\n",
      " [ 65  68]\n",
      " [ 85  93]\n",
      " [100 100]\n",
      " [ 83  76]\n",
      " [ 36  41]\n",
      " [ 84  79]\n",
      " [ 85  84]\n",
      " [ 66  70]\n",
      " [ 71  73]\n",
      " [ 78  73]\n",
      " [ 59  57]\n",
      " [ 77  69]\n",
      " [ 80  92]\n",
      " [ 70  80]\n",
      " [ 79  85]\n",
      " [ 63  73]\n",
      " [ 47  61]\n",
      " [ 76  90]\n",
      " [ 82  88]]\n",
      "[150  87 128 147 152 106 154 107 105 150 113 130 138 101 131 129 189 148\n",
      "  70 128 163  61 160  80 127 152 146 195 132 115 143 176 181 172 185 172\n",
      " 163 159 127 129 137 149 136 133 192 148 162 124 193 128 117 156 131 168\n",
      " 164 109 144 104 166 145 144 170 171 155 138 107 100 138 101 128 114 185\n",
      " 121 124 142 135 115 171 163  70 180 133 178 200 159  77 163 169 136 144\n",
      " 151 116 146 172 150 164 136 108 166 170]\n"
     ]
    }
   ],
   "source": [
    "X = dataset1.iloc[:, :-2].values\n",
    "y = dataset1.iloc[:, 3].values\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "667288e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 69  75]\n",
      " [ 90  90]\n",
      " [ 78  73]\n",
      " [ 43  58]\n",
      " [ 76  80]\n",
      " [100  95]\n",
      " [ 31  39]\n",
      " [ 68  76]\n",
      " [ 79  76]\n",
      " [ 69  73]\n",
      " [ 39  48]\n",
      " [ 86  84]\n",
      " [ 70  66]\n",
      " [ 77  72]\n",
      " [ 66  86]\n",
      " [ 62  67]\n",
      " [ 79  69]\n",
      " [ 68  69]\n",
      " [ 61  66]\n",
      " [ 57  49]\n",
      " [ 59  57]\n",
      " [ 74  71]\n",
      " [ 71  79]\n",
      " [ 92  93]\n",
      " [ 64  68]\n",
      " [ 53  64]\n",
      " [ 72  58]\n",
      " [ 83  89]\n",
      " [ 43  37]\n",
      " [ 67  64]\n",
      " [ 59  54]\n",
      " [ 89  87]\n",
      " [ 45  55]\n",
      " [ 55  49]\n",
      " [ 30  40]\n",
      " [ 36  41]\n",
      " [ 89  92]\n",
      " [ 83  76]\n",
      " [ 67  64]\n",
      " [ 71  73]\n",
      " [ 65  63]\n",
      " [ 56  59]\n",
      " [ 57  71]\n",
      " [ 47  61]\n",
      " [ 76  90]\n",
      " [ 67  61]\n",
      " [ 77  86]\n",
      " [ 70  80]\n",
      " [ 57  64]\n",
      " [ 84  87]\n",
      " [ 76  76]\n",
      " [ 72  87]\n",
      " [ 65  68]\n",
      " [ 78  84]\n",
      " [ 69  60]\n",
      " [ 58  49]\n",
      " [ 76  90]\n",
      " [ 74  64]\n",
      " [ 66  70]\n",
      " [ 57  57]\n",
      " [ 85  84]\n",
      " [ 85  78]\n",
      " [ 33  28]\n",
      " [100 100]\n",
      " [ 81  69]\n",
      " [ 63  73]\n",
      " [ 64  74]\n",
      " [ 67  71]\n",
      " [ 51  73]\n",
      " [ 98  94]]\n",
      "[144 180 151 101 156 195  70 144 155 142  87 170 136 149 152 129 148 137\n",
      " 127 106 116 145 150 185 132 117 130 172  80 131 113 176 100 104  70  77\n",
      " 181 159 131 144 128 115 128 108 166 128 163 150 121 171 152 159 133 162\n",
      " 129 107 166 138 136 114 169 163  61 200 150 136 138 138 124 192]\n",
      "[[ 69  77]\n",
      " [ 84  79]\n",
      " [ 61  67]\n",
      " [ 57  52]\n",
      " [ 58  77]\n",
      " [ 80  92]\n",
      " [ 94  95]\n",
      " [ 65  59]\n",
      " [ 84  80]\n",
      " [ 79  85]\n",
      " [ 88  80]\n",
      " [ 77  69]\n",
      " [ 85  78]\n",
      " [ 47  54]\n",
      " [ 53  54]\n",
      " [ 69  74]\n",
      " [ 80  80]\n",
      " [ 53  74]\n",
      " [ 85  87]\n",
      " [ 54  51]\n",
      " [ 57  76]\n",
      " [ 78  93]\n",
      " [ 68  79]\n",
      " [ 88  97]\n",
      " [ 71  77]\n",
      " [ 93 100]\n",
      " [ 81  73]\n",
      " [ 82  88]\n",
      " [ 85  93]\n",
      " [ 56  59]]\n",
      "[146 163 128 109 135 172 189 124 164 164 168 146 163 101 107 143 160 127\n",
      " 172 105 133 171 147 185 148 193 154 170 178 115]\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "71a25040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "55f56a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146. 163. 128. 109. 135. 172. 189. 124. 164. 164. 168. 146. 163. 101.\n",
      " 107. 143. 160. 127. 172. 105. 133. 171. 147. 185. 148. 193. 154. 170.\n",
      " 178. 115.]\n",
      "[144. 180. 151. 101. 156. 195.  70. 144. 155. 142.  87. 170. 136. 149.\n",
      " 152. 129. 148. 137. 127. 106. 116. 145. 150. 185. 132. 117. 130. 172.\n",
      "  80. 131. 113. 176. 100. 104.  70.  77. 181. 159. 131. 144. 128. 115.\n",
      " 128. 108. 166. 128. 163. 150. 121. 171. 152. 159. 133. 162. 129. 107.\n",
      " 166. 138. 136. 114. 169. 163.  61. 200. 150. 136. 138. 138. 124. 192.]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(y_pred)\n",
    "X_pred= regressor.predict(X_train)  \n",
    "print(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5d0be971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Test Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Train Score: ', regressor.score(X_train, y_train))  \n",
    "print('Test Score: ', regressor.score(X_test, y_test))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a470932c",
   "metadata": {},
   "source": [
    "Applications of linear regression:\n",
    "Market analysis:You can use a regression model to determine how products perform in the market by\n",
    "                establishing the relationships between several quantitative variables, such as social\n",
    "                media engagement, pricing and number of sales. This information allows you to utilise\n",
    "                specific marketing strategies to maximise sales and increase revenue.\n",
    "Financial analysis:Financial analysts use linear models to evaluate a company's\n",
    "                   operational performance and forecast returns on investment.\n",
    "Medicine:Medical researchers can use this regression model to determine the relationship between\n",
    "         independent characteristics, such as age and body weight, and dependent ones, such as blood\n",
    "         pressure. This can help reveal the risk factors associated with diseases. They can use this\n",
    "         information to identify high-risk patients and promote healthy lifestyles.\n",
    "Predicting outcomes,Sports analysis,Environmental health etc.\n",
    "LIMITATIONS OF Linear regression:\n",
    "Linearity: The assumption of linearity between variables restricts linear regressions.The premise of\n",
    "           a straight-line relationship is usually false and may provide inaccurate results.\n",
    "Overfit: It's not recommended to use linear regressions when the observations aren't \n",
    "         proportional to the features. Using it may produce extreme similarities between an \n",
    "         analysis and a data set and may end up failing to produce reliable results and predict\n",
    "         future observations accurately.\n",
    "Outliers: Linear regressions are prone to mistakes and outliers. They multiply the need for \n",
    "          analysts to analyze and remove any anomaly before applying linear regression to the data.\n",
    "Multicollinearity: It's often crucial to remove any trace of multicollinearity because of its \n",
    "                   assumption that no relationship exists among the independent variables.\n",
    "                   You can remove them through dimensionality reduction methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
